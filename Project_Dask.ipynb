{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86d1d639",
   "metadata": {},
   "source": [
    "# Smartphone and Smartwatch Human Activity Recognition (HAR) Model\n",
    "\n",
    "[Eugene Zen](mailto:ezen@ucsd.edu), [Shane Luna](mailto:shluna@ucsd.edu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80f9ca",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[I. Summary](#summary)<br>\n",
    "[II. Dataset Description](#dataset-description)<br>\n",
    "[III. Development](#development)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[A. Dependencies](#development-dependencies)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[B. Load Data](#development-load-data)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[C. Exploratory Data Analysis (EDA)](#development-eda)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[D. Data Preparation](#development-data-preparation)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[E. Model Selection & Training](#development-model-selection-and-training)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[F. Model Testing](#development-model-testing)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[G. Dask Cluster Shutdown](#development-dask-cluster-shutdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf0457",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## I. Summary\n",
    "This notebook presents the development of a Human Activity Recognition (HAR) model that utilizes sensors from both smartphones and smartwatches. The data was originally collected and analyzed by the members of the WISDM (Wireless Sensor Data Mining) Lab in the Department of Computer and Information Science of Fordham University. More information on the original experiment can be found in the publication from 2019 [here](https://ieeexplore.ieee.org/document/8835065). The data was made publicly available on the UCI Machine Learning Repository as the \"WISDM Smartphone and Smartwach Activity and Biometrics Dataset\" and can be found [here](https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7a88a",
   "metadata": {},
   "source": [
    "<a id='dataset-description'></a>\n",
    "## II. Dataset Description\n",
    "\"The 'WISDM Smartphone and Smartwatch Activity and Biometrics Dataset' includes data collected from 51 subjects, each of whom were asked to perform 18 tasks for 3 minutes each. Each subject had a smartwatch placed on his/her dominant hand and a smartphone in their pocket. The data collection was controlled by a custom-made app that ran on the smartphone and smartwatch. The sensor data that was collected was from the accelerometer and gyrocope on both the smartphone and smartwatch, yielding four total sensors.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfed8a",
   "metadata": {},
   "source": [
    "| Summary Item | Description |\n",
    "| --------------- | --------------- |\n",
    "| Number of subjects | 51 |\n",
    "| Number of activities | 18 |\n",
    "| Minutes collected per activity | 3 |\n",
    "| Sensor polling rate | 20Hz |\n",
    "| Smartphone used | Google Nexus 5/5x or Samsung Galaxy S5 |\n",
    "| Smartwatch used | LG G Watch |\n",
    "| Number raw measurements | 15,630,426 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ae5c8",
   "metadata": {},
   "source": [
    "<a id='development'></a>\n",
    "## III. Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65ccba",
   "metadata": {},
   "source": [
    "<a id='development-dependencies'></a>\n",
    "### A. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5711ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start local dask client\n",
    "client = Client(n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805d5fd",
   "metadata": {},
   "source": [
    "<a id='development-load-data'></a>\n",
    "### B. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3560a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    df = dd.read_csv(filepath, sep = ',', header = None)\n",
    "    df.columns = ['subject_id', 'activity_code', 'timestamp', 'x', 'y', 'z']\n",
    "    df['timestamp_dt'] = dd.to_datetime(df['timestamp'], origin='unix') # phone in microseconds / watch in milliseconds -- letting infer\n",
    "    df['z'] = df['z'].str.replace(\";\",\"\").astype('float64') # remove ; and ensure float (having issues with lineterminator)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone Data\n",
    "phone_accel_df = read_file('wisdm-dataset/raw/phone/accel/*.txt')\n",
    "phone_gyro_df = read_file('wisdm-dataset/raw/phone/gyro/*.txt')\n",
    "\n",
    "# Watch Data\n",
    "watch_accel_df = read_file('wisdm-dataset/raw/watch/accel/*.txt')\n",
    "watch_gyro_df = read_file('wisdm-dataset/raw/watch/gyro/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99138d",
   "metadata": {},
   "source": [
    "Referring to the dataset description provided from the WISDM Lab, one would expect to see the following row counts:\n",
    "\n",
    "- raw/phone/accel: 4,804,403\n",
    "- raw/phone/gyro: 3,608,635\n",
    "- raw/watch/accel: 3,777,046\n",
    "- raw/watch/gyro: 3,440,342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Phone Accel:\\t{len(phone_accel_df)}')\n",
    "print(f'Phone Gyro:\\t{len(phone_gyro_df)}')\n",
    "print(f'Watch Accel:\\t{len(watch_accel_df)}')\n",
    "print(f'Watch Gyro:\\t{len(watch_gyro_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a7580",
   "metadata": {},
   "source": [
    "All of the above dataframes are stuctured similarly. A sample output of the column datatypes has been provided below for reference. An additional column, timestamp_dt, was added to the original data by converting the timestamp attribute to a datetime object type. The original timestamp column has been preserved if needed for future enhancements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phone_accel_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece858ce",
   "metadata": {},
   "source": [
    "<a id='development-eda'></a>\n",
    "### C. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15304997",
   "metadata": {},
   "source": [
    "First, a check is done for any null values in the data. As expected, none were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e791866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls\n",
    "\n",
    "print('--Phone Accel--')\n",
    "print(phone_accel_df.isna().sum().compute())\n",
    "\n",
    "print('--Phone Gyro--')\n",
    "print(phone_gyro_df.isna().sum().compute())\n",
    "\n",
    "print('--Watch Accel--')\n",
    "print(watch_accel_df.isna().sum().compute())\n",
    "\n",
    "print('--Watch Gyro--')\n",
    "print(watch_gyro_df.isna().sum().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816a152",
   "metadata": {},
   "source": [
    "Second, a check was done for any missing sensor datasets.\n",
    "\n",
    "i.e. Did all subjects actually do all activites and are readings available for each activity on each sensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e6cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which sensors have missing activities\n",
    "subjects = phone_accel_df['subject_id'].unique().compute()\n",
    "activities = phone_accel_df['activity_code'].unique().compute()\n",
    "\n",
    "subject_activities_df = pd.DataFrame(subjects).merge(pd.DataFrame(activities), how='cross')\n",
    "\n",
    "phone_accel_interval_counts = phone_accel_df.groupby(['subject_id', 'activity_code']).size().rename('phone_accel').reset_index().compute()\n",
    "subject_activities_df = subject_activities_df.merge(phone_accel_interval_counts, on=['subject_id', 'activity_code'], how='left')\n",
    "\n",
    "phone_gyro_interval_counts = phone_gyro_df.groupby(['subject_id', 'activity_code']).size().rename('phone_gyro').reset_index().compute()\n",
    "subject_activities_df = subject_activities_df.merge(phone_gyro_interval_counts, on=['subject_id', 'activity_code'], how='left')\n",
    "\n",
    "watch_accel_interval_counts = watch_accel_df.groupby(['subject_id', 'activity_code']).size().rename('watch_accel').reset_index().compute()\n",
    "subject_activities_df = subject_activities_df.merge(watch_accel_interval_counts, on=['subject_id', 'activity_code'], how='left')\n",
    "\n",
    "watch_gyro_interval_counts = watch_gyro_df.groupby(['subject_id', 'activity_code']).size().rename('watch_gyro').reset_index().compute()\n",
    "subject_activities_df = subject_activities_df.merge(watch_gyro_interval_counts, on=['subject_id', 'activity_code'], how='left')\n",
    "\n",
    "subject_activities_df = subject_activities_df.set_index(['subject_id'])\n",
    "\n",
    "subject_activities_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec31e",
   "metadata": {},
   "source": [
    "Below are the details for which subject activities are missing sensor data. One might also notice that read frequencies are higher for certain sensor data. @20Hz, 3 minutes of activity data should be 3600 readings per activity. For some activities below, it lists > 8000 readings for certain sensors. This is an anomaly called out in the original research publication. It was stated that \"due to the nature of the Android OS, the sampling rate is only taken as a suggestion, so actual sampling rates sometimes differed.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ec66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_activities_df[subject_activities_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c55606",
   "metadata": {},
   "source": [
    "To confirm the sampling rate discrepancy listed above, a test is performed. The main cause of high reads could be due to one of two reasons:\n",
    "1. A difference in sampling rate\n",
    "2. A difference in overall duration (longer duration at the same sampling rate)\n",
    "\n",
    "A test is performed on option #2 above and it is confirmed that all the durations are aproximately the same. It is found that all durations for each acitivty fit between 179 < x < 182 seconds except for one activity recorded on both the watch accelerometer and gyroscope. Therefore, by deduction, the discrepancy above is confirmed to be a difference in sampling rate. Additional confirmation is done later in the train/test step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51015ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = phone_accel_df[['subject_id', 'activity_code', 'timestamp_dt']].groupby(['subject_id', 'activity_code']).agg(['max', 'min']).reset_index()\n",
    "pa['duration'] = pa['timestamp_dt']['max'] - pa['timestamp_dt']['min']\n",
    "pa['duration_s'] = pa['duration'].dt.total_seconds()\n",
    "\n",
    "print(f'total length: {len(pa)}')\n",
    "print(f\"total in range: {len(pa[(pa['duration_s'] > 179) & (pa['duration_s'] < 182)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = phone_gyro_df[['subject_id', 'activity_code', 'timestamp_dt']].groupby(['subject_id', 'activity_code']).agg(['max', 'min']).reset_index()\n",
    "pg['duration'] = pg['timestamp_dt']['max'] - pg['timestamp_dt']['min']\n",
    "pg['duration_s'] = pg['duration'].dt.total_seconds()\n",
    "\n",
    "print(f'total length: {len(pg)}')\n",
    "print(f\"total in range: {len(pg[(pg['duration_s'] > 179) & (pg['duration_s'] < 181)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa = watch_accel_df[['subject_id', 'activity_code', 'timestamp_dt']].groupby(['subject_id', 'activity_code']).agg(['max', 'min']).reset_index()\n",
    "wa['duration'] = wa['timestamp_dt']['max'] - wa['timestamp_dt']['min']\n",
    "wa['duration_s'] = wa['duration'].dt.total_seconds()\n",
    "\n",
    "print(f'total length: {len(wa)}')\n",
    "print(f\"total in range: {len(wa[(wa['duration_s'] > 179) & (wa['duration_s'] < 181)])}\")\n",
    "\n",
    "print(f\"min: {wa['duration_s'].min().compute()}\")\n",
    "print(f\"max: {wa['duration_s'].max().compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg = watch_gyro_df[['subject_id', 'activity_code', 'timestamp_dt']].groupby(['subject_id', 'activity_code']).agg(['max', 'min']).reset_index()\n",
    "wg['duration'] = wg['timestamp_dt']['max'] - wg['timestamp_dt']['min']\n",
    "wg['duration_s'] = wg['duration'].dt.total_seconds()\n",
    "\n",
    "print(f'total length: {len(wg)}')\n",
    "print(f\"total in range: {len(wg[(wg['duration_s'] > 179) & (wg['duration_s'] < 181)])}\")\n",
    "\n",
    "print(f\"min: {wg['duration_s'].min().compute()}\")\n",
    "print(f\"max: {wg['duration_s'].max().compute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff3b3f",
   "metadata": {},
   "source": [
    "Third, a check is performed to confirm if the timestamps among device sensors are synced. This will simplify joining the data in the data preparation step. A test was done by picking a single subject and single activity and checking the starting timestamp. Upon doing so, it was realized that the times/clocks among the different devices (phone vs. watch) may not necessarily be synced. One can ignore the the year/dates provided in the timestamps; those are not believe to be accurate. The times are the more important piece. It is confirmed that their intervals show up appropriately and they are being read in, in the same manner across sensors. It is later clarified from one of the professors/authors in the original publication, if one would like to combined the datasets, to assume the same start time across sensors for each subject activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phone_accel_df[(phone_accel_df['subject_id'] == 1600) & (phone_accel_df['activity_code'] == 'A')]['timestamp_dt'].min().compute())\n",
    "print(phone_gyro_df[(phone_gyro_df['subject_id'] == 1600) & (phone_gyro_df['activity_code'] == 'A')]['timestamp_dt'].min().compute())\n",
    "print(watch_accel_df[(watch_accel_df['subject_id'] == 1600) & (watch_accel_df['activity_code'] == 'A')]['timestamp_dt'].min().compute())\n",
    "print(watch_gyro_df[(watch_gyro_df['subject_id'] == 1600) & (watch_gyro_df['activity_code'] == 'A')]['timestamp_dt'].min().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af78fc",
   "metadata": {},
   "source": [
    "Fourth, a high-level analysis was performed by looking at some visualizations of the tri-axial sensor readings from both the smartphone and the smartwatch. A random suject was picked for the visualization. The efforts of the rest of this notebook aim to assess the distinctness of these patterns for different physical activities. The plots below are currently separated by device sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc7f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    'A': \"Walking\", \n",
    "    'B': \"Jogging\", \n",
    "    'C': \"Stairs\", \n",
    "    'D': \"Sitting\", \n",
    "    'E': \"Standing\", \n",
    "    'F': \"Typing\", \n",
    "    'G': \"Brushing Teeth\", \n",
    "    'H': \"Eating Soup\", \n",
    "    'I': \"Eating Chips\", \n",
    "    'J': \"Eating Pasta\", \n",
    "    'K': \"Drinking from Cup\", \n",
    "    'L': \"Eating Sandwich\", \n",
    "    'M': \"Kicking (Soccer Ball)\", \n",
    "    'O': \"Playing Catch w/Tennis Ball\", \n",
    "    'P': \"Dribbling (Basketball)\", \n",
    "    'Q': \"Writing\", \n",
    "    'R': \"Clapping\", \n",
    "    'S': \"Folding Clothes\"\n",
    "}\n",
    "\n",
    "def plot_activity(df, title=None, x_label=None, y_label=None):\n",
    "    # assuming all 18 activities\n",
    "    \n",
    "    subject_id = df.head(1)['subject_id'].item()\n",
    "    activities = df['activity_code'].unique()\n",
    "    \n",
    "    fig, axs = plt.subplots(6, 3, figsize=(20,20))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    count, i, j = 0, -1, 0\n",
    "    for act in activities:\n",
    "        if count % 3 == 0:\n",
    "            i += 1\n",
    "            j = 0\n",
    "        # do plot stuff #\n",
    "        axs[i, j].plot(range(len(df[df['activity_code'] == act])), df[df['activity_code'] == act]['x'].to_numpy(), c='C0', label='x')\n",
    "        axs[i, j].plot(range(len(df[df['activity_code'] == act])), df[df['activity_code'] == act]['y'].to_numpy(), c='C1', label='y')\n",
    "        axs[i, j].plot(range(len(df[df['activity_code'] == act])), df[df['activity_code'] == act]['z'].to_numpy(), c='C2', label='z')\n",
    "        axs[i, j].set_title(labels_dict[act])\n",
    "        axs[i, j].legend()\n",
    "        #################\n",
    "        count += 1\n",
    "        j += 1\n",
    "    \n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel=x_label, ylabel=y_label)\n",
    "        \n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "        \n",
    "#     plt.savefig('phone_accel.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449df845",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = phone_accel_df['activity_code'].unique().compute()\n",
    "activity = pd.DataFrame()\n",
    "for act in activities:\n",
    "    temp_act = phone_accel_df[(phone_accel_df['subject_id'] == 1600) & (phone_accel_df['activity_code'] == act)].compute()[0:100]\n",
    "    activity = pd.concat([activity, temp_act])\n",
    "plot_activity(activity, title='Subject 1600: Phone Accelerometer', x_label='reading #', y_label='m/s2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea47960",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = phone_gyro_df['activity_code'].unique().compute()\n",
    "activity = pd.DataFrame()\n",
    "for act in activities:\n",
    "    temp_act = phone_gyro_df[(phone_gyro_df['subject_id'] == 1600) & (phone_gyro_df['activity_code'] == act)].compute()[0:100]\n",
    "    activity = pd.concat([activity, temp_act])\n",
    "plot_activity(activity, title='Subject 1600: Phone Gyroscope', x_label='reading #', y_label='radians/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0718ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = watch_accel_df['activity_code'].unique().compute()\n",
    "activity = pd.DataFrame()\n",
    "for act in activities:\n",
    "    temp_act = watch_accel_df[(watch_accel_df['subject_id'] == 1600) & (watch_accel_df['activity_code'] == act)].compute()[0:100]\n",
    "    activity = pd.concat([activity, temp_act])\n",
    "plot_activity(activity, title='Subject 1600: Watch Accelerometer', x_label='reading #', y_label='m/s2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6402a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = watch_gyro_df['activity_code'].unique().compute()\n",
    "activity = pd.DataFrame()\n",
    "for act in activities:\n",
    "    temp_act = watch_gyro_df[(watch_gyro_df['subject_id'] == 1600) & (watch_gyro_df['activity_code'] == act)].compute()[0:100]\n",
    "    activity = pd.concat([activity, temp_act])\n",
    "plot_activity(activity, title='Subject 1600: Watch Gyroscope', x_label='reading #', y_label='radians/s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28210d90",
   "metadata": {},
   "source": [
    "Summary of takeaways from EDA:\n",
    "- Not all subjects performed all activities\n",
    "- Some subjects may have performed certain activites with limited sensors recording\n",
    "- Sensors potentially have different frequencies\n",
    "- Timestamps/clocks between smartphone and smartwatch are not synced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a16de74",
   "metadata": {},
   "source": [
    "<a id='development-data-preparation'></a>\n",
    "### D. Data Preparation\n",
    "\n",
    "*After noticing the timestamps/clocks being out of sync, but also reading that the device data was successfully joined in the original publication, contact was made, for clarifcation, to one of the professors involved/one of the co-authors, Gary Weiss, Professor within the Department of Computer and Information Science at Fordham University. It was clarified that the data was originally aligned on the assumption that each activity had the same start time and that there would not be much drift. For the rest of the analysis in this notebook, it will continue to be done under this same assumption.*\n",
    "\n",
    "The data preparation step will be broken into the following tasks:\n",
    "1. Group the sensor data into x second non-overlapping intervals, for each subject activity.\n",
    "    - x = 3\n",
    "    - aggregate/engineer desired features for each window in this step\n",
    "2. Join the data by timestamp and/or interval index.\n",
    "\n",
    "The following sensor combinations will be evaluated:\n",
    "\n",
    "- **Phone** = phone_accel + phone_gyro\n",
    "- **Watch** = watch_accel + watch_gyro\n",
    "- **Both** = phone_accel + phone_gyro + watch_accel + watch_gyro **(INCOMPLETE)**\n",
    "\n",
    "When training a model based on both, only activity data available with all 4 sensors will be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953b5d5",
   "metadata": {},
   "source": [
    "The following section of code groups the sensor data by the window size prior to joining the respective device's sensors. This is done for both the phone dataseta and the watch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group phone accel by window size\n",
    "phone_accel_grouped_df = phone_accel_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "phone_accel_grouped_mean_df = phone_accel_grouped_df.agg(['mean', 'std']).fillna(0)\n",
    "phone_accel_grouped_mean_df.columns = phone_accel_grouped_mean_df.columns.map('_'.join)\n",
    "phone_accel_grouped_mean_df = phone_accel_grouped_mean_df.reset_index()\n",
    "# phone_accel_grouped_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8eb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group phone gyro by window size\n",
    "phone_gyro_grouped_df = phone_gyro_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "phone_gyro_grouped_mean_df = phone_gyro_grouped_df.agg(['mean', 'std']).fillna(0)\n",
    "phone_gyro_grouped_mean_df.columns = phone_gyro_grouped_mean_df.columns.map('_'.join)\n",
    "phone_gyro_grouped_mean_df = phone_gyro_grouped_mean_df.reset_index()\n",
    "# phone_gyro_grouped_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join phone sensor datasets\n",
    "phone_grouped_means_df = phone_accel_grouped_mean_df.merge(phone_gyro_grouped_mean_df, on=[\"subject_id\", \"activity_code\", \"timestamp_dt\"], how=\"inner\", suffixes=['_accel', '_gyro'])\n",
    "phone_grouped_means_df = phone_grouped_means_df.drop(['timestamp_mean_accel', 'timestamp_std_accel', 'timestamp_mean_gyro', 'timestamp_std_gyro'], axis=1)\n",
    "# phone_grouped_means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group watch accel by window size\n",
    "watch_accel_grouped_df = watch_accel_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "watch_accel_grouped_mean_df = watch_accel_grouped_df.agg(['mean', 'std']).fillna(0)\n",
    "watch_accel_grouped_mean_df.columns = watch_accel_grouped_mean_df.columns.map('_'.join)\n",
    "watch_accel_grouped_mean_df = watch_accel_grouped_mean_df.reset_index()\n",
    "# watch_accel_grouped_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group watch gyro by window size\n",
    "watch_gyro_grouped_df = watch_gyro_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "watch_gyro_grouped_mean_df = watch_gyro_grouped_df.agg(['mean', 'std']).fillna(0)\n",
    "watch_gyro_grouped_mean_df.columns = watch_gyro_grouped_mean_df.columns.map('_'.join)\n",
    "watch_gyro_grouped_mean_df = watch_gyro_grouped_mean_df.reset_index()\n",
    "# watch_gyro_grouped_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff550ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join watch sensor datasets\n",
    "watch_grouped_means_df = watch_accel_grouped_mean_df.merge(watch_gyro_grouped_mean_df, on=[\"subject_id\", \"activity_code\", \"timestamp_dt\"], how=\"inner\", suffixes=['_accel', '_gyro'])\n",
    "watch_grouped_means_df = watch_grouped_means_df.drop(['timestamp_mean_accel', 'timestamp_std_accel', 'timestamp_mean_gyro', 'timestamp_std_gyro'], axis=1)\n",
    "# watch_grouped_means_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c655de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Phone joined length: {len(phone_grouped_means_df)}')\n",
    "print(f'Watch joined length: {len(watch_grouped_means_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d53e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_grouped_clean_df = phone_grouped_means_df.copy()\n",
    "watch_grouped_clean_df = watch_grouped_means_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dbe35d",
   "metadata": {},
   "source": [
    "### ***WORK IN PROGRESS***\n",
    "\n",
    "#### Both = phone_accel + phone_gyro + watch_accel + watch_gyro\n",
    "#### Adjust Subject Activity Start Time to Nearest Minute (Floor) Prior to Grouping Data \n",
    "\n",
    "Shifting of times of the data was done in preparation to use with the pd.Grouper functionality. pd.Grouper works off whole numbers. To avoid small groupings of interval data at the start of the dataset, a shifting of the timestamps is done to the nearest whole second (floor). In this step, the min() date for each subject activity was taken and rounded down to the nearest whole second. A difference was taken from this new value and the original min() value to capture an offset value. This offset value was then applied to the rest of the subject activity dataset slightly shifting the whole subset of data for each subject activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3eb88",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "1. Incorporate interval number when grouping to be used for joining the device datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8499cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create directories to persist data if they don't already exist\n",
    "# outdir = './data_persist'\n",
    "# if not os.path.exists(outdir):\n",
    "#     os.makedirs(f'{outdir}/phone/accel')\n",
    "#     os.makedirs(f'{outdir}/phone/gyro')\n",
    "#     os.makedirs(f'{outdir}/watch/accel')\n",
    "#     os.makedirs(f'{outdir}/watch/gyro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_files(outputdirectory, filename_suffix, df):\n",
    "#     subjects = df['subject_id'].unique().compute()\n",
    "#     activities = df['activity_code'].unique().compute()\n",
    "    \n",
    "#     # persist original df for performance gains\n",
    "#     # create copy for usage below\n",
    "#     df = df.persist()\n",
    "#     df_shift = df.copy()\n",
    "    \n",
    "#     min_times = df_shift.groupby(['subject_id', 'activity_code']).min().reset_index().compute()\n",
    "#     df_shift['timestamp_shift_dt'] = ''\n",
    "    \n",
    "#     count = 0\n",
    "#     for sub in subjects:\n",
    "#         subject_df = df_shift[(df_shift['subject_id'] == sub)].persist()\n",
    "#         for act in activities:\n",
    "#             min_ts = min_times[(min_times['subject_id'] == sub) & (min_times['activity_code'] == act)]['timestamp_dt']\n",
    "#             if len(min_ts == 1):\n",
    "#                 min_ts = min_ts.item()\n",
    "#                 floor_ts = min_ts.floor('min')\n",
    "#                 offset_ts = min_ts-floor_ts\n",
    "#                 subject_df['timestamp_shift_dt'] = subject_df['timestamp_shift_dt'].mask(((subject_df['activity_code'] == act)), (subject_df['timestamp_dt'] - offset_ts))\n",
    "#         subject_df['timestamp_shift_dt'] = dd.to_datetime(subject_df['timestamp_shift_dt'], origin='unix')\n",
    "#         subject_df = subject_df.compute()\n",
    "#         subject_df.to_csv(f'{outputdirectory}{sub}_{filename_suffix}.csv', sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# write_files('./data_persist/phone/accel/', 'phone_accel', phone_accel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3184b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# write_files('./data_persist/phone/gyro/', 'phone_gyro', phone_gyro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21493e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# write_files('./data_persist/watch/accel/', 'watch_accel', watch_accel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# write_files('./data_persist/watch/gyro/', 'watch_gyro', watch_gyro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read files back in\n",
    "# def read_file_new(filepath):\n",
    "#     df = dd.read_csv(filepath, sep = ',', header=0)\n",
    "#     df['timestamp_dt'] = dd.to_datetime(df['timestamp_dt'], origin='unix')\n",
    "#     df['timestamp_shift_dt'] = dd.to_datetime(df['timestamp_shift_dt'], origin='unix')\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phone Data\n",
    "# phone_accel_shift_df = read_file_new('data_persist/phone/accel/*.csv')\n",
    "# phone_gyro_shift_df = read_file_new('data_persist/phone/gyro/*.csv')\n",
    "\n",
    "# # Watch Data\n",
    "# watch_accel_shift_df = read_file_new('data_persist/watch/accel/*.csv')\n",
    "# watch_gyro_shift_df = read_file_new('data_persist/watch/gyro/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91632df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confrim lengths back to original files\n",
    "# print('--NEW--')\n",
    "# print(f'Phone Accel:\\t{len(phone_accel_shift_df)}')\n",
    "# print(f'Phone Gyro:\\t{len(phone_gyro_shift_df)}')\n",
    "# print(f'Watch Accel:\\t{len(watch_accel_shift_df)}')\n",
    "# print(f'Watch Gyro:\\t{len(watch_gyro_shift_df)}')\n",
    "# print('--ORIG--')\n",
    "# print(f'Phone Accel:\\t{len(phone_accel_df)}')\n",
    "# print(f'Phone Gyro:\\t{len(phone_gyro_df)}')\n",
    "# print(f'Watch Accel:\\t{len(watch_accel_df)}')\n",
    "# print(f'Watch Gyro:\\t{len(watch_gyro_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea56892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Usage - missing interval numbers for join afterwards\n",
    "# phone_gyro_grouped_df = phone_gyro_shift_df.copy()\n",
    "# phone_gyro_grouped_df = phone_gyro_grouped_df.drop('timestamp_dt', axis=1)\n",
    "# phone_gyro_grouped_df = phone_gyro_grouped_df.set_index('timestamp_shift_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c586c",
   "metadata": {},
   "source": [
    "### ***PREV WORK / ARCHIVE***\n",
    "\n",
    "This section of code below was used for joining the device dataset first and then grouping. This was done for each respective device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86b9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone\n",
    "# phone_combined_df = phone_accel_df.merge(phone_gyro_df, on=['subject_id', 'activity_code', 'timestamp_dt'], how='inner', suffixes=['_accel', '_gyro'])\n",
    "# phone_combined_df = phone_combined_df.drop(['timestamp_gyro'], axis=1)\n",
    "# phone_combined_df = phone_combined_df.rename(columns={'timestamp_accel': 'timestamp'})\n",
    "# phone_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch\n",
    "# watch_combined_df = watch_accel_df.merge(watch_gyro_df, on=['subject_id', 'activity_code', 'timestamp_dt'], how='inner', suffixes=['_accel', '_gyro'])\n",
    "# watch_combined_df = watch_combined_df.drop(['timestamp_gyro'], axis=1)\n",
    "# watch_combined_df = watch_combined_df.rename(columns={'timestamp_accel': 'timestamp'})\n",
    "# watch_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone & Watch\n",
    "# phone_watch_combined_df = phone_combined_df.merge(watch_combined_df, on=['subject_id', 'activity_code', 'timestamp_dt'], how='inner', suffixes=['_phone', '_watch'])\n",
    "# phone_watch_combined_df.head()\n",
    "# phone and watch data do not have times synced -- currently unable to use together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62289860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Phone: {len(phone_combined_df)}')\n",
    "# print(f'Watch: {len(watch_combined_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906232b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix_phone = phone_combined_df.corr()\n",
    "# corr_matrix_phone.compute().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fca734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_matrix_watch = watch_combined_df.corr()\n",
    "# corr_matrix_watch.compute().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab30e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone_grouped_df = phone_combined_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "# watch_grouped_df = watch_combined_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee997b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp grouping/interval count check\n",
    "# size = phone_grouped_df.size().rename('count').to_frame()\n",
    "# size.compute().value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Grouper check (to understand if it keeps the first or last of the interval)\n",
    "# https://stackoverflow.com/questions/35898667/group-by-time-and-other-column-in-pandas\n",
    "# sample_df = phone_accel_df.head(60)\n",
    "# sample_group_df = sample_df.set_index('timestamp_dt').groupby(['subject_id', 'activity_code', pd.Grouper(freq='3S')])\n",
    "\n",
    "# print(sample_df.head())\n",
    "# sample_group_df.agg(['mean', 'count'])\n",
    "\n",
    "# Findings:\n",
    "# groups by looking at whole second intervals\n",
    "# shows timestamp for first time in interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone_grouped_means_df = phone_grouped_df.mean().reset_index()\n",
    "# phone_grouped_counts_df = phone_grouped_df.size().rename('count').reset_index()\n",
    "# phone_grouped_means_df = phone_grouped_means_df.merge(phone_grouped_counts_df, on=['subject_id', 'activity_code', 'timestamp_dt'])\n",
    "# print(f'Phone full: {len(phone_grouped_means_df)}')\n",
    "\n",
    "# phone_grouped_clean_df = phone_grouped_means_df[phone_grouped_means_df['count'] > 20]\n",
    "# print(f'Phone > 20: {len(phone_grouped_clean_df)}')\n",
    "\n",
    "# watch_grouped_means_df = watch_grouped_df.mean().reset_index()\n",
    "# watch_grouped_counts_df = watch_grouped_df.size().rename('count').reset_index()\n",
    "# watch_grouped_means_df = watch_grouped_means_df.merge(watch_grouped_counts_df, on=['subject_id', 'activity_code', 'timestamp_dt'])\n",
    "# print(f'Watch full: {len(watch_grouped_means_df)}')\n",
    "\n",
    "# watch_grouped_clean_df = watch_grouped_means_df[watch_grouped_means_df['count'] > 20]\n",
    "# print(f'Watch > 20: {len(watch_grouped_clean_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone = phone_grouped_clean_df['activity_code'].value_counts().rename('total').reset_index().compute().sort_values(by=['index'], ascending=True)\n",
    "# watch = watch_grouped_clean_df['activity_code'].value_counts().rename('total').reset_index().compute().sort_values(by=['index'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = phone['total'].sum()\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "\n",
    "# plt.plot(phone['index'], (phone['total']/total*100), label='phone')\n",
    "# plt.plot(watch['index'], (watch['total']/total*100), label='watch')\n",
    "\n",
    "# plt.title('Data Distribution by Activity Code')\n",
    "# plt.xlabel('Activity Code')\n",
    "# plt.ylabel('% of Respective Dataset')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17b15e",
   "metadata": {},
   "source": [
    "### *** END PREV WORK / ARCHIVE***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8878491",
   "metadata": {},
   "source": [
    "<a id='development-model-selection-and-training'></a>\n",
    "### E. Model Selection & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split with 80-20 split\n",
    "import dask_ml.model_selection\n",
    "\n",
    "data_columns = ['x_mean_accel', 'y_mean_accel', 'z_mean_accel', 'x_mean_gyro', 'y_mean_gyro', 'z_mean_gyro', 'x_std_accel', 'y_std_accel', 'z_std_accel', 'x_std_gyro', 'y_std_gyro', 'z_std_gyro']\n",
    "label_columns = ['activity_code']\n",
    "\n",
    "# drop subject and timestamps from train data\n",
    "phone_data_all = phone_grouped_clean_df[data_columns]\n",
    "phone_labels_all = phone_grouped_clean_df[label_columns]\n",
    "\n",
    "# drop subject and timestamps from train data\n",
    "watch_data_all = watch_grouped_clean_df[data_columns]\n",
    "watch_labels_all = watch_grouped_clean_df[label_columns]\n",
    "\n",
    "X_train_phone, X_test_phone, y_train_phone, y_test_phone = dask_ml.model_selection.train_test_split(phone_data_all, phone_labels_all, shuffle = True, random_state=0, test_size = 0.2)\n",
    "X_train_watch, X_test_watch, y_train_watch, y_test_watch = dask_ml.model_selection.train_test_split(watch_data_all, watch_labels_all, shuffle = True, random_state=0, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12003d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train_phone: {len(X_train_phone)}')\n",
    "print(f'X_test_phone: {len(X_test_phone)}')\n",
    "print(f'y_train_phone: {len(y_train_phone)}')\n",
    "print(f'y_test_phone: {len(y_test_phone)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433c3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train_watch: {len(X_train_watch)}')\n",
    "print(f'X_test_watch: {len(X_test_watch)}')\n",
    "print(f'y_train_watch: {len(y_train_watch)}')\n",
    "print(f'y_test_watch: {len(y_test_watch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42082e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_phone = RandomForestClassifier(random_state=0)\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    clf_phone.fit(X_train_phone, y_train_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48176c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clf_watch = RandomForestClassifier(random_state=0)\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    clf_watch.fit(X_train_watch, y_train_watch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af404a",
   "metadata": {},
   "source": [
    "<a id='development-model-testing'></a>\n",
    "### F. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    predicted_labels_phone = clf_phone.predict(X_test_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ecfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    predicted_labels_watch = clf_watch.predict(X_test_watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    print(accuracy_score(y_test_phone, predicted_labels_phone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0937343",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    print(accuracy_score(y_test_watch, predicted_labels_watch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phone_labels = np.unique(y_test_phone)\n",
    "unique_watch_labels = np.unique(y_test_watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65534ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Confusion Matrix: Phone\n",
    "cm_phone = confusion_matrix(y_test_phone, predicted_labels_phone, labels = unique_phone_labels)\n",
    "\n",
    "display_labels = [\"Walking\", \"Jogging\", \"Stairs\", \"Sitting\", \"Standing\", \"Typing\", \"Brushing Teeth\", \"Eating Soup\", \"Eating Chips\", \"Eating Pasta\", \"Drinking from Cup\", \"Eating Sandwich\", \"Kicking (Soccer Ball)\", \"Playing Catch w/Tennis Ball\", \"Dribbling (Basketball)\", \"Writing\", \"Clapping\", \"Folding Clothes\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "sns.heatmap(cm_phone, annot=True, fmt='g', xticklabels = display_labels, yticklabels = display_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af830f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Confusion Matrix: Watch\n",
    "cm_watch = confusion_matrix(y_test_watch, predicted_labels_watch, labels = unique_watch_labels)\n",
    "\n",
    "display_labels = [\"Walking\", \"Jogging\", \"Stairs\", \"Sitting\", \"Standing\", \"Typing\", \"Brushing Teeth\", \"Eating Soup\", \"Eating Chips\", \"Eating Pasta\", \"Drinking from Cup\", \"Eating Sandwich\", \"Kicking (Soccer Ball)\", \"Playing Catch w/Tennis Ball\", \"Dribblinlg (Basketball)\", \"Writing\", \"Clapping\", \"Folding Clothes\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.xaxis.set_label_position('top')\n",
    "sns.heatmap(cm_watch, annot=True, fmt='g', xticklabels = display_labels, yticklabels = display_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb748447",
   "metadata": {},
   "source": [
    "<a id='development-dask-cluster-shutdown'></a>\n",
    "### G. Dask Cluster Shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebceb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
